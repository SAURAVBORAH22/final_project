# toxic_comment_classifier
## Problem Statement and Background
The background for the problem originates from the multitude of online forums, where-in people participate actively and make comments. As the comments some times may be abusive, insulting or even hate-based, it becomes the responsibility of the hosting organizations to ensure that these conversations are not of negative type. The task was thus to build a model which could make prediction to classify the comments into various categories. 
## The exact problem statement was thus as below:
Given a group of sentences or paragraphs, used as a comment by a user in an online platform, classify it to belong to one or more of the following categories â€” toxic, severe-toxic, obscene, threat, insult or identity-hate with either approximate probabilities or discrete values (0/1).
## Multilabel vs Multiclass classification ?
As the task was to figure out whether the data belongs to zero, one, or more than one categories out of the six listed above, the first step before working on the problem was to distinguish between multi-label and multi-class classification.
In multi-class classification, we have one basic assumption that our data can belong to only one label out of all the labels we have. For example, a given picture of a fruit may be an apple, orange or guava only and not a combination of these.
In multi-label classification, data can belong to more than one label simultaneously. For example, in our case a comment may be toxic, obscene and insulting at the same time. It may also happen that the comment is non-toxic and hence does not belong to any of the six labels.
Hence, I had a multi-label classification problem to solve. The next step was to gain some useful insights from data which would aid further problem solving.

# Deployment Link
https://toxiccommentclassifier.herokuapp.com/
